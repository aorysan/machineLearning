{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pertemuan 13\n",
        "\n",
        "## Aryo Adi Putro - 2341720084 | TI-3G\n",
        "\n",
        "### Praktikum 1"
      ],
      "metadata": {
        "id": "1zwYxaMCY0zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5NbF8P4Y0N4",
        "outputId": "472eb169-e756-4a31-d76e-c9b2d894f5b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2524562170195149\n",
            "Epoch 1000, Loss: 0.2479426031566117\n",
            "Epoch 2000, Loss: 0.22900892438374704\n",
            "Epoch 3000, Loss: 0.16737799348167076\n",
            "Epoch 4000, Loss: 0.14272604477851042\n",
            "Epoch 5000, Loss: 0.13523209626970908\n",
            "Epoch 6000, Loss: 0.1320005614245339\n",
            "Epoch 7000, Loss: 0.13025927904492002\n",
            "Epoch 8000, Loss: 0.1291860380460197\n",
            "Epoch 9000, Loss: 0.12846379952211984\n",
            "Prediksi:\n",
            "[[0.05075925]\n",
            " [0.95392217]\n",
            " [0.49575307]\n",
            " [0.50281705]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tugas 1"
      ],
      "metadata": {
        "id": "iVtOfDT7akBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLFHfZ28ampF",
        "outputId": "260c274b-db87-476a-8407-7cb6b3e59d07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.26954856264278615\n",
            "Epoch 1000, Loss: 0.21222330562206343\n",
            "Epoch 2000, Loss: 0.16444988676468758\n",
            "Epoch 3000, Loss: 0.08721159693369084\n",
            "Epoch 4000, Loss: 0.030519338948917903\n",
            "Epoch 5000, Loss: 0.015040675699832308\n",
            "Epoch 6000, Loss: 0.009373101175484847\n",
            "Epoch 7000, Loss: 0.0066371408281449915\n",
            "Epoch 8000, Loss: 0.005071917681586245\n",
            "Epoch 9000, Loss: 0.004073311277381689\n",
            "Prediksi:\n",
            "[[0.04706083]\n",
            " [0.93395664]\n",
            " [0.9531185 ]\n",
            " [0.06910152]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hasil loss setelah perubahan hidden layer mengalami perubahan lebih cepat dengan sebelumnya."
      ],
      "metadata": {
        "id": "CuYYGVAdbSwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "# Fungsi aktivasi output (tetap sigmoid)\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40SFYSrsawU4",
        "outputId": "97ae4113-5e4b-4c97-b209-1f4f14e872e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3274780407035275\n",
            "Epoch 1000, Loss: 0.012797082733424602\n",
            "Epoch 2000, Loss: 0.003283471866346602\n",
            "Epoch 3000, Loss: 0.001730956726043575\n",
            "Epoch 4000, Loss: 0.001146816158135167\n",
            "Epoch 5000, Loss: 0.0008463615651895275\n",
            "Epoch 6000, Loss: 0.0006661559173500909\n",
            "Epoch 7000, Loss: 0.0005467478016979456\n",
            "Epoch 8000, Loss: 0.00046239544032793036\n",
            "Epoch 9000, Loss: 0.0003996816119159116\n",
            "Prediksi:\n",
            "[[0.02970009]\n",
            " [0.98605912]\n",
            " [0.98605934]\n",
            " [0.01163533]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Perbandingan loss sebelum menggunakna relU, loss berkurang lebih lamban hingga epoch. sedangkan setelah menggunakan relU, loss berkurang lebih cepat."
      ],
      "metadata": {
        "id": "zPdcj8q1ccPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Praktikum 2"
      ],
      "metadata": {
        "id": "FKcJsWadeeKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Fix: ganti 'sparse' jadi 'sparse_output'\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Normalisasi data (opsional tapi direkomendasikan)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYb43FLIeaRb",
        "outputId": "59d9f76c-150b-449d-dfba-6c31a54f1928"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0567 - loss: 1.1783    \n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2595 - loss: 1.1020 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4361 - loss: 1.0343 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5132 - loss: 1.0452 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6296 - loss: 1.0085 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6973 - loss: 0.9229 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.8802 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6314 - loss: 0.8615 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.8264 \n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.7383 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.7276 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.6985 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7696 - loss: 0.6870 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.6053 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.5537 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.5078 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 0.4730 \n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.4962 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.4519 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 0.4544 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.3295 \n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 0.3669 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.3299 \n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.3157 \n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.3085 \n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.3013 \n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.2830 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.2916 \n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.2969 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.2487 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.2417 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 0.2662 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.2273 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.2012 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.2263 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 0.2126 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.2468 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1876 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.1736 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1789 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.1750 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.1755 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.1808 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1807 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1670 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.1209\n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9335 - loss: 0.1888\n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9632 - loss: 0.1390\n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9770 - loss: 0.1197\n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.1396  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0941\n",
            "Akurasi: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tugas 2\n",
        "\n",
        "- Ubah jumlah neuron layer"
      ],
      "metadata": {
        "id": "YHw53ygNjQ1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Fix untuk versi scikit-learn baru\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Normalisasi data (direkomendasikan)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bangun model dengan jumlah neuron hidden layer diubah (16 dan 12)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJawmdj1jMa1",
        "outputId": "3189862b-6d35-4d0c-c870-091ade32a828"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5709 - loss: 0.8512\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.7537 \n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6267 - loss: 0.7230 \n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.6331 \n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6597 - loss: 0.6131 \n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6741 - loss: 0.5481 \n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6713 - loss: 0.5101 \n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6906 - loss: 0.4874 \n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.4724\n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7066 - loss: 0.4752 \n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.3780 \n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8302 - loss: 0.3976 \n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.4187 \n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.3602 \n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.3280 \n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.3421 \n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.3194\n",
            "Epoch 18/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.3342 \n",
            "Epoch 19/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.2842 \n",
            "Epoch 20/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.2771 \n",
            "Epoch 21/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9161 - loss: 0.2831\n",
            "Epoch 22/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.2676 \n",
            "Epoch 23/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9351 - loss: 0.2490\n",
            "Epoch 24/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9379 - loss: 0.2505\n",
            "Epoch 25/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.2292\n",
            "Epoch 26/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2450\n",
            "Epoch 27/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9596 - loss: 0.2034 \n",
            "Epoch 28/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.2325\n",
            "Epoch 29/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.2060 \n",
            "Epoch 30/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.2201 \n",
            "Epoch 31/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.1789 \n",
            "Epoch 32/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.2113 \n",
            "Epoch 33/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1664 \n",
            "Epoch 34/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.1578 \n",
            "Epoch 35/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.1377 \n",
            "Epoch 36/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.1529 \n",
            "Epoch 37/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1673 \n",
            "Epoch 38/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1546 \n",
            "Epoch 39/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1682 \n",
            "Epoch 40/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1450 \n",
            "Epoch 41/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.1184 \n",
            "Epoch 42/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1181 \n",
            "Epoch 43/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.1101 \n",
            "Epoch 44/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0917 \n",
            "Epoch 45/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9590 - loss: 0.1291 \n",
            "Epoch 46/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1311 \n",
            "Epoch 47/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9654 - loss: 0.1051 \n",
            "Epoch 48/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.1142 \n",
            "Epoch 49/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0858 \n",
            "Epoch 50/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1041 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0766\n",
            "Akurasi: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Akurasi sebelum dan sesudah perubahan memiliki hasil akurasi yang sama."
      ],
      "metadata": {
        "id": "zxVbZoGSjUc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y_raw = iris.target\n",
        "\n",
        "# Jadikan binary: Setosa = 0, Versicolor+Virginica = 1\n",
        "y = (y_raw != 0).astype(int).reshape(-1, 1)\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(5000):\n",
        "    # Forward\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        loss = np.mean(error ** 2)\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output\n",
        "print(\"\\nPrediksi (0=setosa, 1=non-setosa):\")\n",
        "print(a2.round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVqmc4XLjlj7",
        "outputId": "b95c62f2-8ef3-4452-a193-b7f6c1f32c0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2526657491044251\n",
            "Epoch 500, Loss: 0.009958535932735782\n",
            "Epoch 1000, Loss: 0.006980303342123861\n",
            "Epoch 1500, Loss: 0.006783695582928303\n",
            "Epoch 2000, Loss: 0.006709027857690365\n",
            "Epoch 2500, Loss: 0.006667902368115621\n",
            "Epoch 3000, Loss: 0.006640480669650402\n",
            "Epoch 3500, Loss: 0.006619693393394723\n",
            "Epoch 4000, Loss: 0.006602263109557919\n",
            "Epoch 4500, Loss: 0.006586289399720513\n",
            "\n",
            "Prediksi (0=setosa, 1=non-setosa):\n",
            "[[0.004]\n",
            " [0.02 ]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.005]\n",
            " [0.008]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.01 ]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.005]\n",
            " [0.004]\n",
            " [0.01 ]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.006]\n",
            " [0.004]\n",
            " [0.056]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.005]\n",
            " [0.004]\n",
            " [0.006]\n",
            " [0.01 ]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.008]\n",
            " [0.007]\n",
            " [0.008]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.005]\n",
            " [0.004]\n",
            " [0.977]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.01 ]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.004]\n",
            " [0.005]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.987]\n",
            " [0.989]\n",
            " [0.983]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.985]\n",
            " [0.989]\n",
            " [0.979]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.979]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.933]\n",
            " [0.922]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.979]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.984]\n",
            " [0.987]\n",
            " [0.989]\n",
            " [0.987]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.983]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.987]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.984]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.988]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.989]\n",
            " [0.978]\n",
            " [0.987]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]\n",
        "y_raw = iris.target\n",
        "\n",
        "# Jadikan binary: Setosa = 0, Versicolor+Virginica = 1\n",
        "y = (y_raw != 0).astype(int).reshape(-1, 1)\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Aktivasi\n",
        "# Fungsi aktivasi ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(5000):\n",
        "    # Forward\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        loss = np.mean(error ** 2)\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output\n",
        "print(\"\\nPrediksi (0=setosa, 1=non-setosa):\")\n",
        "print(a2.round(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTLZRwRuv_Lc",
        "outputId": "6df71251-c8d0-4d2e-9348-eaf33da7a464"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.4386703622505442\n",
            "Epoch 500, Loss: 0.22727198172651025\n",
            "Epoch 1000, Loss: 0.2310674566568263\n",
            "Epoch 1500, Loss: 0.2273086003487769\n",
            "Epoch 2000, Loss: 0.14273004321191826\n",
            "Epoch 2500, Loss: 0.011775265762807264\n",
            "Epoch 3000, Loss: 0.006920231033414807\n",
            "Epoch 3500, Loss: 0.006749773985412717\n",
            "Epoch 4000, Loss: 0.00668880830326907\n",
            "Epoch 4500, Loss: 0.00665641833810185\n",
            "\n",
            "Prediksi (0=setosa, 1=non-setosa):\n",
            "[[0.006]\n",
            " [0.025]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.007]\n",
            " [0.01 ]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.013]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.011]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.008]\n",
            " [0.006]\n",
            " [0.068]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.007]\n",
            " [0.006]\n",
            " [0.008]\n",
            " [0.011]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.01 ]\n",
            " [0.009]\n",
            " [0.009]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.982]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.013]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.006]\n",
            " [0.007]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.987]\n",
            " [0.988]\n",
            " [0.984]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.986]\n",
            " [0.988]\n",
            " [0.981]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.98 ]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.943]\n",
            " [0.921]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.981]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.985]\n",
            " [0.987]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.987]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.985]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.984]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.988]\n",
            " [0.978]\n",
            " [0.988]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Perbedaan hasil sigmoid dengan relU adalah hasil dari sigmoid lebih sedikit lebih bagus (0.001)"
      ],
      "metadata": {
        "id": "OgZTqdUPucSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Praktikum 3"
      ],
      "metadata": {
        "id": "55QzP_RQwUTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Contoh dataset (buat dummy data)\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train, y_train, epochs=100)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Prediksi:\", model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU3dK28AwR3r",
        "outputId": "3619f9ba-f870-4d73-c160-db0633d1f6ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.7341\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.7170\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.6999\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.6830\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.6662\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.6495\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.6329\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.6164\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.6001\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.5839\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.5678\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5518\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.5360\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.5203\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.5047\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4892\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4739\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.4586\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.4435\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 1.4286\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.4137\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.3990\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.3844\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.3699\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.3556\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 1.3414\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.3273\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.3133\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 1.2994\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 1.2857\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 1.2720\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2585\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.2451\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.2318\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.2187\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.2056\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.1927\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.1799\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.1672\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.1546\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1421\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 1.1297\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 1.1175\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.1053\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.0933\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.0813\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.0696\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.0580\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.0464\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.0350\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.0237\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 1.0125\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.0014\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.9904\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.9795\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.9687\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.9580\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.9474\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.9369\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.9265\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.9162\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9059\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.8958\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.8858\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.8758\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8659\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.8562\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.8465\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.8369\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.8273\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.8180\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.8088\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.7997\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7907\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7818\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.7729\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7642\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7555\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7469\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7384\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.7300\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.7217\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7135\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.7054\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.6974\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.6894\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6815\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.6737\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6659\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6582\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.6506\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.6430\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.6356\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.6281\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6208\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.6135\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.6063\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.5991\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.5920\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.5850\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "Prediksi: [[-0.00968671]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tugas 4"
      ],
      "metadata": {
        "id": "2mkkhXpkxMI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dataset sederhana\n",
        "data = pd.DataFrame({\n",
        "    'luas': [50, 60, 70, 80, 90],\n",
        "    'harga': [500, 600, 700, 800, 900]\n",
        "})\n",
        "\n",
        "X = data[['luas']]\n",
        "y = data[['harga']]\n",
        "\n",
        "# Normalisasi\n",
        "scalerX = StandardScaler()\n",
        "X = scalerX.fit_transform(X)\n",
        "\n",
        "scalerY = StandardScaler()\n",
        "y = scalerY.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Fungsi untuk membangun model\n",
        "def build_model(lr):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='mse'\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Coba beberapa learning rate\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "results = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\n=== Training dengan learning rate = {lr} ===\")\n",
        "    model = build_model(lr)\n",
        "    history = model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "    final_loss = history.history['loss'][-1]\n",
        "    results[lr] = final_loss\n",
        "    print(f\"Final loss: {final_loss}\")\n",
        "\n",
        "# Ringkasan hasil\n",
        "print(\"\\n=== Perbandingan Loss ===\")\n",
        "for lr, loss in results.items():\n",
        "    print(f\"LR {lr} -> Loss: {loss}\")\n"
      ],
      "metadata": {
        "id": "iMXy6RVExK_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP regresi (Keras)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Load\n",
        "housing = fetch_california_housing() # Changed to fetch_california_housing\n",
        "X = housing.data; y = housing.target\n",
        "\n",
        "# 2. Preprocess\n",
        "scaler = StandardScaler(); Xs = scaler.fit_transform(X)\n",
        "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Build model\n",
        "model = Sequential([\n",
        "Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "Dense(32, activation='relu'),\n",
        "Dense(1)\n",
        "])\n",
        "model.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "\n",
        "# 4. Train\n",
        "h = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "# 5. Plot\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1); plt.plot(h.history['loss'], label='train_loss'); plt.plot(h.history['val_loss'], label='val_loss'); plt.legend(); plt.title('MSE')\n",
        "plt.subplot(1,2,2); plt.plot(h.history['mae'], label='train_mae'); plt.plot(h.history['val_mae'], label='val_mae'); plt.legend(); plt.title('MAE')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pred = model.predict(X_val)\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_val, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "D8w4alnWxO6s",
        "outputId": "113d9429-3169-4c14-80f3-3f6513e9c266"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "RMSE: 0.5167234173071305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tugas Praktikum"
      ],
      "metadata": {
        "id": "Ms1hUAbay1rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),             # Ubah gambar 28x28 → vektor 784\n",
        "    Dense(128, activation='relu'),             # Hidden layer 1\n",
        "    Dense(64, activation='relu'),              # Hidden layer 2\n",
        "    Dense(10, activation='softmax')            # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRmZvPtEy3V4",
        "outputId": "6a4efb56-6423-4e17-ce3e-c0c51c7eb9d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.4307\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.1075\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9787 - loss: 0.0690\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0509\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0386\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9742 - loss: 0.0997\n",
            "Akurasi pada data uji: 0.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Coba dengan beberapa parameter lain:\n",
        "1. Ubah jumlah neuron di hidden layer (misal: 256 dan 128).\n",
        "2. Tambahkan satu hidden layer lagi.\n",
        "3. Bandingkan akurasi dan waktu pelatihan.\n",
        "4. Eksperimen dengan fungsi aktivasi Sigmoid vs ReLU.\n",
        "\n"
      ],
      "metadata": {
        "id": "TWmM3tYO0vh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "def run_experiment(h1, h2, h3=None, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    model.add(Dense(h1, activation=activation))\n",
        "    model.add(Dense(h2, activation=activation))\n",
        "\n",
        "    if h3:\n",
        "        model.add(Dense(h3, activation=activation))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=1,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Kurangi epoch + atur batch\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=128, callbacks=[callback], verbose=0)\n",
        "    duration = time.time() - start\n",
        "\n",
        "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Neuron {h1}-{h2}-{h3}, activation={activation}\")\n",
        "    print(f\"Akurasi: {acc:.4f}, Waktu: {duration:.2f} detik\\n\")\n",
        "\n",
        "    return acc, duration\n",
        "\n",
        "acc1, t1 = run_experiment(128, 64, activation='relu')\n",
        "\n",
        "acc2, t2 = run_experiment(256, 128, activation='relu')\n",
        "\n",
        "acc3, t3 = run_experiment(256, 128, 64, activation='relu')\n",
        "\n",
        "acc4, t4 = run_experiment(128, 64, 32, activation='sigmoid')\n",
        "\n",
        "print(\"\\n=== HASIL PERBANDINGAN EKSPERIMEN ===\")\n",
        "print(f\"1. ReLU (128-64)                → Acc: {acc1:.4f}, Time: {t1:.2f} s\")\n",
        "print(f\"2. ReLU (256-128)               → Acc: {acc2:.4f}, Time: {t2:.2f} s\")\n",
        "print(f\"3. ReLU (256-128-64)            → Acc: {acc3:.4f}, Time: {t3:.2f} s\")\n",
        "print(f\"4. Sigmoid (128-64-32)          → Acc: {acc4:.4f}, Time: {t4:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSz5OpcD00Io",
        "outputId": "9448ba90-ce96-4bbc-8293-c9c823d41c66"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neuron 128-64-None, activation=relu\n",
            "Akurasi: 0.9747, Waktu: 19.38 detik\n",
            "\n",
            "Neuron 256-128-None, activation=relu\n",
            "Akurasi: 0.9771, Waktu: 24.98 detik\n",
            "\n",
            "Neuron 256-128-64, activation=relu\n",
            "Akurasi: 0.9792, Waktu: 24.75 detik\n",
            "\n",
            "Neuron 128-64-32, activation=sigmoid\n",
            "Akurasi: 0.9610, Waktu: 18.54 detik\n",
            "\n",
            "\n",
            "=== HASIL PERBANDINGAN EKSPERIMEN ===\n",
            "1. ReLU (128-64)                → Acc: 0.9747, Time: 19.38 s\n",
            "2. ReLU (256-128)               → Acc: 0.9771, Time: 24.98 s\n",
            "3. ReLU (256-128-64)            → Acc: 0.9792, Time: 24.75 s\n",
            "4. Sigmoid (128-64-32)          → Acc: 0.9610, Time: 18.54 s\n"
          ]
        }
      ]
    }
  ]
}